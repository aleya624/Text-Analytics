{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_poC30bqQIrR",
        "outputId": "612989a4-9d1c-46ad-b67c-73fe0081a734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reviews have been saved to ACE_Rent_Car_Review.csv\n"
          ]
        }
      ],
      "source": [
        "# ==========================================================\n",
        "# Lab         : Lab Assignment 1 - Web Scraping\n",
        "# Name        : SHAZA ADELINA BINTI KHAIRULLAH\n",
        "# Student ID  : SN0107857\n",
        "# Name        : NURALEYA BINTI AZIZAN\n",
        "# Student ID  : IS01084475\n",
        "# ==========================================================\n",
        "\n",
        "from bs4 import BeautifulSoup #to parse and extract HTML content\n",
        "import requests #to send HTTP request to website\n",
        "import csv\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "\n",
        "# Function to extract reviews from A page\n",
        "def scrape_page(soup, reviews_list):\n",
        "\n",
        "    # Find all the review containers\n",
        "    for review_element in soup.find_all('div', class_='styles_cardWrapper__g8amG styles_show__Z8n7u'):\n",
        "\n",
        "        # Extract username\n",
        "        user_element = review_element.find('span',class_='CDS_Typography_appearance-default__68c681 CDS_Typography_prettyStyle__68c681 CDS_Typography_heading-xs__68c681 styles_consumerName__xKr9c')\n",
        "        user = user_element.text if user_element else 'N/A' #if username not entered\n",
        "\n",
        "        # Extract review's comment\n",
        "        comment_element = review_element.find('p', class_='CDS_Typography_appearance-default__68c681 CDS_Typography_prettyStyle__68c681 CDS_Typography_body-l__68c681')\n",
        "        comment = comment_element.text if comment_element else '' #if comment not filled\n",
        "\n",
        "        # Extract review date from <time> tag\n",
        "        date_element = review_element.find('time')\n",
        "        date = date_element.get('datetime')\n",
        "\n",
        "        # Store extracted data into list as dictionary\n",
        "        reviews_list.append({\n",
        "            'User': user,\n",
        "            'Date': date,\n",
        "            'Comment': comment\n",
        "        })\n",
        "\n",
        "\n",
        "# the url of the main rent a car page\n",
        "base_url = 'https://www.trustpilot.com/review/acerentacar.com'\n",
        "\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "# Empty list to store all reviews scraped\n",
        "reviews = []\n",
        "\n",
        "\n",
        "# Function to scrape Multiple pages\n",
        "def scrape_all_pages(url):\n",
        "\n",
        "    page_count = 0   # Counter to limit web scraping to 5 pages only\n",
        "\n",
        "    #a loop to check if url exists AND page less than 5\n",
        "    while url and page_count < 5:\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Extract reviews from current page\n",
        "        scrape_page(soup, reviews)\n",
        "\n",
        "        # Find \"Next page\" button\n",
        "        next_button = soup.find('a', attrs={'name': 'pagination-button-next'})\n",
        "\n",
        "        # Check if next_button is found before trying to get its 'href' attribute\n",
        "        if next_button:\n",
        "            next_link = next_button.get('href')\n",
        "            url = 'https://www.trustpilot.com' + next_link\n",
        "        else:\n",
        "            # If no next button is found, set url to None to terminate the loop\n",
        "            url = None\n",
        "\n",
        "        page_count += 1   # Increase page counter\n",
        "\n",
        "\n",
        "# Call function to start scraping\n",
        "scrape_all_pages(base_url)\n",
        "\n",
        "\n",
        "# Store extracted data into CSV file\n",
        "with open('ACE_Rent_Car_Review.csv', 'w', encoding='utf-8', newline='') as csvfile:\n",
        "\n",
        "    # Define column headers\n",
        "    fieldnames = ['User', 'Date', 'Comment']\n",
        "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "    # Write header row\n",
        "    writer.writeheader()\n",
        "\n",
        "    # Write each review into CSV file\n",
        "    for review in reviews:\n",
        "        writer.writerow(review)\n",
        "\n",
        "\n",
        "print(\"Reviews have been saved to ACE_Rent_Car_Review.csv\")"
      ]
    }
  ]
}